{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral extraction pipeline\n",
    "\n",
    "## 1. Introduction & User Guide\n",
    "\n",
    "### Why is this useful?\n",
    "In remote sensing and forestry (especially with hyperspectral or high-resolution lidar data), raster files are often significantly larger than available system RAM. A standard approach of \"load everything, then process\" leads to memory error crashes or system freezing.\n",
    "\n",
    "**Phytospatial** solves this by offering an adaptive extraction engine that abstracts away the complexity of memory management. It provides four strategies:\n",
    "\n",
    "1.  **In-Memory:** Fastest, but requires the whole file to fit in RAM.\n",
    "2.  **Tiled:** Standard streaming (512x512 windows). Safe for any file size but slightly slower due to overhead.\n",
    "3.  **Blocked:** Optimized streaming that reads data using the file's native internal structure (chunks/strips), minimizing disk seeking.\n",
    "4.  **Auto:** The \"production\" mode. It statically analyzes your hardware and the file structure to pick the best strategy automatically.\n",
    "\n",
    "This tutorial demonstrates how to extract spectral information from rasters (either as statistics or raw pixel data) for individual tree crowns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports\n",
    "\n",
    "First, we import the necessary modules. We will use `phytospatial`'s tiered architecture:\n",
    "* **Tier 1 (IO/Layer):** For direct data handling.\n",
    "* **Tier 2 (Resources):** For safety checks.\n",
    "* **Tier 3 (Extract):** The high-level orchestration engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Phytospatial imports\n",
    "from phytospatial.raster.io import load\n",
    "from phytospatial.raster.resources import estimate_memory_safety, analyze_structure, ProcessingMode\n",
    "from phytospatial.extract import extract_to_dataframe\n",
    "\n",
    "# Configure logging to see phytospatial's decision making process\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    force=True\n",
    ")\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Configuration\n",
    "\n",
    "Define your input paths here.\n",
    "* **Crowns:** A vector file (Shapefile, GeoJSON, GeoPackage) containing polygons.\n",
    "* **Raster:** A geospatial raster (TIFF, ENVI, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these paths to point to your actual data\n",
    "DATA_DIR = Path(\"data\")\n",
    "CROWNS_FILE = DATA_DIR / \"crowns.shp\"\n",
    "RASTER_FILE = DATA_DIR / \"input_hdrs/mosaic_test.hdr\" # or .tif\n",
    "OUTPUT_DIR = DATA_DIR / \"results\"\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Crowns: {CROWNS_FILE}\")\n",
    "print(f\"Raster: {RASTER_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform checks (Resource Analysis)\n",
    "\n",
    "Before running any heavy code, it is best practice to perform a \"Pre-flight Check.\" This uses `estimate_memory_safety` and `analyze_structure` to peek at the file metadata without loading the pixel data.\n",
    "\n",
    "**Why do this?**\n",
    "* Prevents crashes before they happen.\n",
    "* Tells you if your file is \"efficient\" (tiled internally) or \"inefficient\" (striped/scanline), which informs your processing strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CROWNS_FILE.exists() or not RASTER_FILE.exists():\n",
    "    print(\"⚠️ Error: One or more input files do not exist. Please check paths.\")\n",
    "else:\n",
    "    print(f\"--- Inspecting {RASTER_FILE.name} --- make\")\n",
    "\n",
    "    # Check Memory Safety\n",
    "    estimate = estimate_memory_safety(RASTER_FILE)\n",
    "    \n",
    "    print(f\"Raw Data Size:    {estimate.raw_bytes / (1024**3):.2f} GB\")\n",
    "    print(f\"Required RAM:     {estimate.total_required_bytes / (1024**3):.2f} GB (includes safety overhead)\")\n",
    "    print(f\"Available RAM:    {estimate.available_system_bytes / (1024**3):.2f} GB\")\n",
    "    print(f\"Is Safe to Load?  {'✅ YES' if estimate.is_safe else '❌ NO'}\")\n",
    "    \n",
    "    # Check File Structure\n",
    "    struct = analyze_structure(RASTER_FILE)\n",
    "    print(f\"\\nInternal Structure: {'Tiled' if struct.is_tiled else 'Striped/Other'}\")\n",
    "    print(f\"Block Shape:        {struct.block_shape}\")\n",
    "    print(f\"Efficiency Score:   {struct.efficiency_score:.2f} (1.0 is perfect)\")\n",
    "    \n",
    "    print(f\"\\nRecommended Mode:   {estimate.recommendation.value.upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pipeline A: The \"Happy Path\" (In-Memory)\n",
    "\n",
    "If the check says \"YES\", `In-Memory` is the fastest method. It loads the entire raster object into Python's heap.\n",
    "\n",
    "**Use case:** Small study areas, individual tiles, or machines with massive RAM (64GB+)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Check safety first to avoid crashing the kernel\n",
    "estimate = estimate_memory_safety(RASTER_FILE)\n",
    "\n",
    "if estimate.is_safe:\n",
    "    print(\"Loading raster into memory...\")\n",
    "    # Explicitly load the raster object first\n",
    "    raster = load(RASTER_FILE)\n",
    "    \n",
    "    print(\"Extracting features...\")\n",
    "    df_memory = extract_to_dataframe(\n",
    "        raster_input=raster,\n",
    "        vector_input=CROWNS_FILE,\n",
    "        threshold=0.001\n",
    "    )\n",
    "    \n",
    "    output_path = OUTPUT_DIR / \"stats_memory.csv\"\n",
    "    df_memory.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Saved {len(df_memory)} rows to {output_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Skipping In-Memory pipeline: Raster is too large for this machine.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pipeline B: Tiled Streaming (The Safety Net)\n",
    "\n",
    "If your raster is massive (for example 50GB), you cannot load it. `Tiled` mode creates a virtual grid over the file and processes it one window at a time.\n",
    "\n",
    "**Use case:** Massive mosaics or files with inefficient internal structures (scanline/striped TIFFs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Starting Tiled extraction (Virtual 512x512 grid)...\")\n",
    "\n",
    "# Notice we pass the file PATH, not the loaded object\n",
    "df_tiled = extract_to_dataframe(\n",
    "    raster_input=RASTER_FILE,\n",
    "    vector_input=CROWNS_FILE,\n",
    "    tile_mode=\"tiled\",\n",
    "    tile_size=512,  # Adjustable window size\n",
    "    threshold=0.001\n",
    ")\n",
    "\n",
    "output_path = OUTPUT_DIR / \"stats_tiled.csv\"\n",
    "    df_tiled.to_csv(output_path, index=False)\n",
    "print(f\"✓ Saved {len(df_tiled)} rows to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pipeline C: Blocked Streaming (Native IO)\n",
    "\n",
    "If your file is a Cloud Optimized GeoTIFF (COG) or uses internal tiling, `Blocked` mode is superior to `Tiled`. It reads data exactly as it sits on the disk, creating zero read-overhead.\n",
    "\n",
    "**Use case:** Optimized formats (COGs) or ENVI files with good interleaving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Only run this if the structure analysis suggested it's efficient\n",
    "struct = analyze_structure(RASTER_FILE)\n",
    "\n",
    "if struct.is_efficient:\n",
    "    print(f\"Starting Blocked extraction (Native {struct.block_shape})...\")\n",
    "\n",
    "    df_blocked = extract_to_dataframe(\n",
    "        raster_input=RASTER_FILE,\n",
    "        vector_input=CROWNS_FILE,\n",
    "        tile_mode=\"blocked\",\n",
    "        threshold=0.001\n",
    "    )\n",
    "    \n",
    "    output_path = OUTPUT_DIR / \"stats_blocked.csv\"\n",
    "    df_blocked.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Saved {len(df_blocked)} rows to {output_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ Skipping Blocked pipeline: File structure is inefficient (likely striped).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pipeline D: Auto Mode (Production Ready)\n",
    "\n",
    "In a production script, you don't want to manually check `if estimate.is_safe` every time. Use `tile_mode=\"auto\"`.\n",
    "\n",
    "**How it works:**\n",
    "1.  It checks your available RAM.\n",
    "2.  If it fits, it uses `In-Memory` (Fastest).\n",
    "3.  If not, it checks the file structure.\n",
    "4.  If the structure is good, it uses `Blocked`.\n",
    "5.  If the structure is bad, it falls back to `Tiled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Starting Auto extraction (Letting the engine decide)...\")\n",
    "\n",
    "df_auto = extract_to_dataframe(\n",
    "    raster_input=RASTER_FILE,\n",
    "    vector_input=CROWNS_FILE,\n",
    "    tile_mode=\"auto\",  # The magic switch\n",
    "    threshold=0.001\n",
    ")\n",
    "\n",
    "output_path = OUTPUT_DIR / \"stats_auto.csv\"\n",
    "df_auto.to_csv(output_path, index=False)\n",
    "print(f\"✓ Saved {len(df_auto)} rows to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Inspecting Results\n",
    "\n",
    "Finally, let's look at the data we extracted. The dataframe will contain the Crown ID, Species, and the calculated statistics for every band in the raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the result\n",
    "print(f\"Extraction Shape: {df_auto.shape}\")\n",
    "df_auto.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
